{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a9a021-b431-4179-b7ae-c44e20d6c450",
   "metadata": {},
   "source": [
    "### European Cities Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c454361a-29a3-438d-ab63-ff452db1db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded file: E:\\Bicocca\\Data Management\\best_cities_for_a_workation.csv\n",
      "\n",
      "Total number of cities: 147\n",
      "\n",
      "Number of European cities: 66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. File Path and Data Loading\n",
    "# --------------------------------------------------\n",
    "file_path = r\"E:\\Bicocca\\Data Management\\best_cities_for_a_workation.csv\"\n",
    "\n",
    "try:\n",
    "    # Read CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded file: {file_path}\\n\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Basic Dataset Overview\n",
    "    # --------------------------------------------------\n",
    "    total_cities = len(df)\n",
    "    print(f\"Total number of cities: {total_cities}\\n\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Filter Cities Located in Europe\n",
    "    # --------------------------------------------------\n",
    "    europe_countries = [\n",
    "        'Germany', 'France', 'United Kingdom', 'Italy', 'Switzerland', 'Poland', 'Ukraine',\n",
    "        'Netherlands', 'Greece', 'Sweden', 'Belgium', 'Austria', 'Denmark', 'Norway',\n",
    "        'Ireland', 'Romania', 'Hungary', 'Czechia', 'Czech Republic', 'Luxembourg', 'Finland',\n",
    "        'Croatia', 'Cyprus', 'Iceland', 'Albania', 'Estonia', 'Bulgaria', 'Malta',\n",
    "        'Slovenia', 'Latvia', 'Belarus', 'Slovakia', 'Moldova', 'Serbia', 'Montenegro',\n",
    "        'Bosnia and Herzegovina', 'North Macedonia', 'Portugal', 'Spain', 'Turkey',\n",
    "        'Russia', 'Georgia', 'Azerbaijan', 'Kazakhstan'\n",
    "    ]\n",
    "\n",
    "    european_cities_df = df[df['Country'].isin(europe_countries)].copy()\n",
    "\n",
    "    europe_cities_count = len(european_cities_df)\n",
    "    print(f\"Number of European cities: {europe_cities_count}\\n\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782c67b-f8cc-4130-ac2c-b5ce30334fed",
   "metadata": {},
   "source": [
    "### Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "372dba82-16f6-462a-b7d7-aec21dad424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Column Names:\n",
      "['rank', 'city', 'country', 'wifi_speed_mbps', 'coworking_count', 'coffee_price', 'taxi_price_km', 'two_beers_price', 'one_bed_apt_price', 'meal_price', 'sunshine_hours', 'attractions_count', 'ig_photos_count']\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# Rename Dataset Columns for Better Readability\n",
    "# --------------------------------------------------\n",
    "# This mapping converts long, descriptive column names\n",
    "# into short, clean, and code-friendly names\n",
    "# --------------------------------------------------\n",
    "column_mapping = {\n",
    "    'Ranking': 'rank',\n",
    "    'City': 'city',\n",
    "    'Country': 'country',\n",
    "\n",
    "    # Remote work related\n",
    "    'Remote connection: Average WiFi speed (Mbps per second)': 'wifi_speed_mbps',\n",
    "    'Co-working spaces: Number of co-working spaces': 'coworking_count',\n",
    "\n",
    "    # Cost-related\n",
    "    'Caffeine: Average price of buying a coffee': 'coffee_price',\n",
    "    'Travel: Average price of taxi (per km)': 'taxi_price_km',\n",
    "    'After-work drinks: Average price for 2 beers in a bar': 'two_beers_price',\n",
    "    'Accommodation: Average price of 1 bedroom apartment per month': 'one_bed_apt_price',\n",
    "    'Food: Average cost of a meal at a local, mid-level restaurant': 'meal_price',\n",
    "\n",
    "    # Lifestyle & environment\n",
    "    'Climate: Average number of sunshine hours': 'sunshine_hours',\n",
    "    'Tourist attractions: Number of ‘Things to do’ on Tripadvisor': 'attractions_count',\n",
    "    'Instagramability: Number of photos with #': 'ig_photos_count'\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Apply the column renaming to the DataFrame\n",
    "# --------------------------------------------------\n",
    "# inplace=True modifies the existing DataFrame directly\n",
    "# --------------------------------------------------\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Verify the updated column names\n",
    "# --------------------------------------------------\n",
    "print(\"New Column Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6bf01-71bc-452c-8e13-ab68e59d6e50",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98d11117-992e-4d42-80bf-bf61c975e299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "rank                 0\n",
      "city                 0\n",
      "country              0\n",
      "wifi_speed_mbps      0\n",
      "coworking_count      0\n",
      "coffee_price         0\n",
      "taxi_price_km        0\n",
      "two_beers_price      0\n",
      "one_bed_apt_price    0\n",
      "meal_price           0\n",
      "sunshine_hours       0\n",
      "attractions_count    0\n",
      "ig_photos_count      0\n",
      "dtype: int64\n",
      "\n",
      "Cleaned Data Preview:\n",
      "\n",
      "Final Columns:\n",
      "['rank', 'city', 'country', 'wifi_speed_mbps', 'coworking_count', 'coffee_price', 'taxi_price_km', 'two_beers_price', 'one_bed_apt_price', 'meal_price', 'sunshine_hours', 'attractions_count', 'ig_photos_count']\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "\n",
    "# --------------------------------------------------\n",
    "# a. Handle Missing Values\n",
    "# --------------------------------------------------\n",
    "print(\"Missing values before handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# --------------------------------------------------\n",
    "# b. Correct Data Types\n",
    "# --------------------------------------------------\n",
    "# Columns that should contain numeric values\n",
    "# (use standardized column names)\n",
    "numeric_cols = [\n",
    "    'wifi_speed_mbps',\n",
    "    'coworking_count',\n",
    "    'coffee_price',\n",
    "    'taxi_price_km',\n",
    "    'two_beers_price',\n",
    "    'one_bed_apt_price',\n",
    "    'meal_price',\n",
    "    'sunshine_hours',\n",
    "    'attractions_count',\n",
    "    'ig_photos_count'\n",
    "]\n",
    "\n",
    "# Keep only columns that actually exist (prevents KeyError)\n",
    "existing_numeric_cols = [col for col in numeric_cols if col in df.columns]\n",
    "\n",
    "# Convert numeric columns safely\n",
    "df[existing_numeric_cols] = df[existing_numeric_cols].astype(float)\n",
    "\n",
    "# Convert remaining columns\n",
    "df['rank'] = df['rank'].astype(int)\n",
    "df['city'] = df['city'].astype(str)\n",
    "df['country'] = df['country'].astype(str)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# c. Remove Leading and Trailing Spaces\n",
    "# --------------------------------------------------\n",
    "df['city'] = df['city'].str.strip()\n",
    "df['country'] = df['country'].str.strip()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# d. Normalize City and Country Names\n",
    "# --------------------------------------------------\n",
    "# Example: München → Munchen\n",
    "df['city'] = df['city'].apply(lambda x: unidecode.unidecode(x))\n",
    "df['country'] = df['country'].apply(lambda x: unidecode.unidecode(x))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# e. Preview Cleaned Data\n",
    "# --------------------------------------------------\n",
    "print(\"\\nCleaned Data Preview:\")\n",
    "df.head()\n",
    "\n",
    "print(\"\\nFinal Columns:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db611a3-c0cb-4260-b84c-4a1aedf25672",
   "metadata": {},
   "source": [
    "### Feature Engineering: Beer Price Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9baac669-1e5e-4e65-96c8-2654e171f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the column exists\n",
    "if 'two_beers_price' in df.columns:\n",
    "    # Convert to numeric (handles strings or bad values)\n",
    "    df['two_beers_price'] = pd.to_numeric(df['two_beers_price'], errors='coerce')\n",
    "\n",
    "    # Create single beer price\n",
    "    df['beer_price'] = df['two_beers_price'] / 2\n",
    "\n",
    "    # Drop the old column\n",
    "    df.drop(columns=['two_beers_price'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b4041-d577-448a-b461-51c3ad5ee7d1",
   "metadata": {},
   "source": [
    "### Geographic Overview and Target European Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8cab888d-2201-4c70-8be8-09f676fc9c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== UNIQUE COUNTRIES =====\n",
      "['Argentina', 'Australia', 'Austria', 'Belarus', 'Belgium', 'Bolivia', 'Brazil', 'Bulgaria', 'Burma/Myanmar', 'Cambodia', 'Canada', 'Chile', 'China', 'Colombia', 'Costa Rica', 'Croatia', 'Czech Republic', 'Denmark', 'Ecuador', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hawaii', 'Hong Kong', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy', 'Japan', 'Kuwait', 'Laos', 'Latvia', 'Lebanon', 'Lithuania', 'Malaysia', 'Malta', 'Mexico', 'Morocco', 'Nepal', 'Netherlands', 'New Zealand', 'Norway', 'Oman', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Qatar', 'Romania', 'Russia', 'Senegal', 'Serbia', 'Singapore', 'Slovenia', 'South Africa', 'South Korea', 'Spain', 'Sri Lanka', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand', 'Turkey', 'Ukraine', 'United Arab Emirates', 'United Kingdom', 'United States', 'Uruguay', 'Vietnam']\n",
      "\n",
      "===== UNIQUE CITIES =====\n",
      "['Abu Dhabi', 'Adelaide', 'Amsterdam', 'Arequipa', 'Athens', 'Auckland', 'Bangkok', 'Barcelona', 'Beijing', 'Beirut', 'Belfast', 'Belgrade', 'Berlin', 'Bordeaux', 'Boston', 'Brisbane', 'Brussels', 'Bucharest', 'Budapest', 'Buenos Aires', 'Calgary', 'Cancun', 'Cape Town', 'Cartagena', 'Chiang Mai', 'Chicago', 'Cologne', 'Colombo', 'Copenhagen', 'Dakar', 'Doha', 'Dresden', 'Dubai', 'Dublin', 'Dubrovnik', 'Dusseldorf', 'Edinburgh', 'Edmonton', 'Faro', 'Florence', 'Frankfurt', 'Geneva', 'Glasgow', 'Hamburg', 'Hannover', 'Hanoi', 'Helsinki', 'Ho Chi Minh City', 'Hoi An', 'Hong Kong', 'Honolulu', 'Houston', 'Hvar', 'Istanbul', 'Jakarta', 'Johannesburg', 'Kathmandu', 'Krakow', 'Kuala Lumpur', 'Kuwait City', 'Kyiv', 'Kyoto', 'La Paz', 'Las Vegas', 'Lima', 'Lisbon', 'Liverpool', 'Ljubljana', 'London', 'Los Angeles', 'Lyon', 'Madrid', 'Malaga', 'Manchester', 'Manila', 'Marrakech', 'Marseille', 'Medellin', 'Melbourne', 'Mexico City', 'Miami', 'Milan', 'Minsk', 'Montevideo', 'Montreal', 'Moscow', 'Mumbai', 'Munich', 'Muscat', 'Naples', 'New Delhi', 'New Orleans', 'New York', 'Oaxaca', 'Osaka', 'Oslo', 'Ottawa', 'Palma de Mallorca', 'Paris', 'Perth', 'Phnom Penh', 'Phoenix', 'Phuket', 'Pokhara', 'Portland', 'Porto', 'Prague', 'Quito', 'Reykjavik', 'Riga', 'Rio de Janeiro', 'Rome', 'Rotterdam', 'Salzburg', 'San Diego', 'San Francisco', 'San Jose', 'Santiago', 'Sao Paulo', 'Seoul', 'Seville', 'Shanghai', 'Siem Reap', 'Singapore', 'Sofia', 'Split', 'St. Petersburg', 'Stockholm', 'Stuttgart', 'Sydney', 'Taipei', 'Tallinn', 'Tel Aviv', 'Tokyo', 'Toronto', 'Valencia', 'Valletta', 'Vancouver', 'Vienna', 'Vientiane', 'Vilnius', 'Warsaw', 'Washington DC', \"Xi'an\", 'Yangon', 'Zagreb', 'Zurich']\n",
      "\n",
      "===== UNIQUE EUROPEAN CITIES IN DATASET =====\n",
      "['Amsterdam', 'Athens', 'Barcelona', 'Belfast', 'Belgrade', 'Berlin', 'Bordeaux', 'Brussels', 'Bucharest', 'Budapest', 'Cologne', 'Copenhagen', 'Dresden', 'Dublin', 'Dubrovnik', 'Dusseldorf', 'Edinburgh', 'Faro', 'Florence', 'Frankfurt', 'Geneva', 'Glasgow', 'Hamburg', 'Hannover', 'Helsinki', 'Hvar', 'Istanbul', 'Krakow', 'Kyiv', 'Lisbon', 'Liverpool', 'Ljubljana', 'London', 'Lyon', 'Madrid', 'Malaga', 'Manchester', 'Marseille', 'Milan', 'Minsk', 'Moscow', 'Munich', 'Naples', 'Oslo', 'Palma de Mallorca', 'Paris', 'Porto', 'Prague', 'Reykjavik', 'Riga', 'Rome', 'Rotterdam', 'Salzburg', 'Seville', 'Sofia', 'Split', 'St. Petersburg', 'Stockholm', 'Stuttgart', 'Tallinn', 'Valencia', 'Valletta', 'Vienna', 'Vilnius', 'Warsaw', 'Zagreb', 'Zurich']\n",
      "\n",
      "Total unique European cities in dataset: 67\n",
      "\n",
      "Total target European cities (after removing 3): 64\n",
      "Cities found in dataset: 64\n",
      "\n",
      "All target cities are present in dataset.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# GEOGRAPHIC OVERVIEW & TARGET EUROPEAN CITIES\n",
    "# ======================================================\n",
    "\n",
    "# --- Unique countries & cities in dataset ---\n",
    "print(\"\\n===== UNIQUE COUNTRIES =====\")\n",
    "print(sorted(df['country'].dropna().unique()))\n",
    "\n",
    "print(\"\\n===== UNIQUE CITIES =====\")\n",
    "print(sorted(df['city'].dropna().unique()))\n",
    "\n",
    "\n",
    "# --- Define European countries (EU + non-EU + transcontinental) ---\n",
    "europe = [\n",
    "    # European Union (27)\n",
    "    'Austria','Belgium','Bulgaria','Croatia','Cyprus','Czech Republic','Denmark',\n",
    "    'Estonia','Finland','France','Germany','Greece','Hungary','Ireland','Italy',\n",
    "    'Latvia','Lithuania','Luxembourg','Malta','Netherlands','Poland','Portugal',\n",
    "    'Romania','Slovakia','Slovenia','Spain','Sweden',\n",
    "\n",
    "    # Non-EU European countries\n",
    "    'Albania','Andorra','Iceland','Liechtenstein','Monaco','Montenegro',\n",
    "    'North Macedonia','Norway','San Marino','Serbia','Switzerland',\n",
    "    'United Kingdom','Vatican City',\n",
    "\n",
    "    # Transcontinental / often included\n",
    "    'Russia','Turkey','Kazakhstan','Georgia','Azerbaijan',\n",
    "\n",
    "    # Post-Soviet European states\n",
    "    'Belarus','Moldova','Ukraine',\n",
    "\n",
    "    # Special / disputed / micro-territories\n",
    "    'Kosovo (Disputed Territory)',\n",
    "    'Isle of Man','Guernsey','Jersey','Faroe Islands','Gibraltar'\n",
    "]\n",
    "\n",
    "\n",
    "# --- Standardize city names for consistency ---\n",
    "city_name_mapping = {\n",
    "    'Krakow (Cracow)': 'Krakow',\n",
    "    'Kiev (Kyiv)': 'Kyiv',\n",
    "    'Seville (Sevilla)': 'Seville',\n",
    "    'Hanover': 'Hannover',\n",
    "    'Saint Petersburg': 'St. Petersburg'\n",
    "}\n",
    "df['city'] = df['city'].replace(city_name_mapping)\n",
    "\n",
    "\n",
    "# --- Unique European cities in dataset ---\n",
    "unique_european_cities = sorted(\n",
    "    df[df['country'].isin(europe)]['city'].dropna().unique()\n",
    ")\n",
    "print(\"\\n===== UNIQUE EUROPEAN CITIES IN DATASET =====\")\n",
    "print(unique_european_cities)\n",
    "print(f\"\\nTotal unique European cities in dataset: {len(unique_european_cities)}\")\n",
    "\n",
    "\n",
    "# --- Refined target European cities (64 cities) ---\n",
    "significant_european_cities = [\n",
    "    'Lisbon','Barcelona','Budapest','Istanbul','Bucharest','Madrid','Sofia',\n",
    "    'Krakow','Belgrade','Prague','Porto','Valencia','Kyiv','Moscow','Berlin',\n",
    "    'Vienna','Malaga','Seville','Rome','Athens','Warsaw','Minsk','Paris',\n",
    "    'Ljubljana','Florence','Liverpool','Tallinn','Zagreb','Hamburg','Naples',\n",
    "    'Milan','Split','Brussels','Dublin','Riga','Lyon','Palma de Mallorca',\n",
    "    'Vilnius','London','Stockholm','Munich','Marseille','Cologne','Amsterdam',\n",
    "    'Dusseldorf','Helsinki','Frankfurt','Stuttgart','Hannover','Copenhagen',\n",
    "    'Dresden','Manchester','Rotterdam','St. Petersburg','Edinburgh','Dubrovnik',\n",
    "    'Oslo','Glasgow','Belfast','Salzburg','Zurich','Geneva','Valletta','Reykjavik'\n",
    "]\n",
    "cities_to_remove = {'Bordeaux', 'Faro', 'Hvar'}\n",
    "target_cities = {city for city in significant_european_cities if city not in cities_to_remove}\n",
    "\n",
    "# --- Filter dataset to refined European cities ---\n",
    "df_filtered = df[df['city'].isin(target_cities)].drop_duplicates(subset='city').reset_index(drop=True)\n",
    "df_filtered['city_index'] = df_filtered.index + 1\n",
    "\n",
    "print(f\"\\nTotal target European cities (after removing 3): {len(target_cities)}\")\n",
    "print(f\"Cities found in dataset: {len(df_filtered)}\")\n",
    "missing_cities = sorted(target_cities - set(df_filtered['city']))\n",
    "if missing_cities:\n",
    "    print(\"\\nMissing cities:\")\n",
    "    print(missing_cities)\n",
    "else:\n",
    "    print(\"\\nAll target cities are present in dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6d8e0-db26-4f54-b317-f363e3b8095b",
   "metadata": {},
   "source": [
    "### Export Filtered Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2300df28-0eb2-4302-95e7-02f34e5294ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as: best_significant_european_workation_cities.csv\n",
      "Directory: C:\\Users\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# File name\n",
    "file_name = 'best_significant_european_workation_cities.csv'\n",
    "\n",
    "try:\n",
    "    # Save the filtered DataFrame\n",
    "    df_filtered.to_csv(file_name, index=False, encoding='utf-8')\n",
    "    print(f\"File saved as: {file_name}\")\n",
    "    print(f\"Directory: {os.getcwd()}\")\n",
    "except NameError:\n",
    "    print(\"ERROR: 'df_filtered' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
