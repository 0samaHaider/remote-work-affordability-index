{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf1015e-eaba-4366-8b5e-1510da747294",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d81a41-af94-434c-bfd5-8c610aff26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import unidecode\n",
    "import re\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b6d2e5-d691-4093-81da-6fdc6fc5430f",
   "metadata": {},
   "source": [
    "### Configuration & City Lists (Crime Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4451cf60-6933-4f79-99ec-cf72ff18ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of significant European cities (aligned with source naming)\n",
    "SIGNIFICANT_EUROPEAN_CITIES = [\n",
    "    'Lisbon', 'Barcelona', 'Budapest', 'Istanbul', 'Bucharest', 'Madrid', 'Sofia',\n",
    "    'Krakow (Cracow)', 'Belgrade', 'Prague', 'Porto', 'Valencia', 'Kiev (Kyiv)',\n",
    "    'Moscow', 'Berlin', 'Vienna', 'Malaga', 'Seville (Sevilla)', 'Rome', 'Faro',\n",
    "    'Athens', 'Warsaw', 'Minsk', 'Paris', 'Ljubljana', 'Florence', 'Liverpool',\n",
    "    'Tallinn', 'Zagreb', 'Hamburg', 'Naples', 'Milan', 'Split', 'Brussels',\n",
    "    'Dublin', 'Riga', 'Lyon', 'Palma de Mallorca', 'Vilnius', 'London',\n",
    "    'Stockholm', 'Munich', 'Marseille', 'Cologne', 'Amsterdam', 'Hvar',\n",
    "    'Dusseldorf', 'Helsinki', 'Bordeaux', 'Frankfurt', 'Stuttgart',\n",
    "    'Hanover', 'Copenhagen', 'Dresden', 'Manchester', 'Rotterdam',\n",
    "    'Saint Petersburg', 'Edinburgh', 'Dubrovnik', 'Oslo', 'Glasgow',\n",
    "    'Belfast', 'Salzburg', 'Zurich', 'Geneva', 'Valletta', 'Reykjavik'\n",
    "]\n",
    "\n",
    "# Cities excluded due to inconsistent or missing data\n",
    "CITIES_TO_EXCLUDE = [\n",
    "    'Bordeaux',\n",
    "    'Faro',\n",
    "    'Hvar'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61762166-1dcc-4383-92ad-976865d7eabb",
   "metadata": {},
   "source": [
    "### Numbeo URLs (Crime Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0542f6-b429-4927-a294-c2e3ffa6ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS_CRIME = {\n",
    "    '2025_Current': 'https://www.numbeo.com/crime/rankings_current.jsp',\n",
    "    '2023_Integration': 'https://www.numbeo.com/crime/rankings.jsp?title=2023'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a3eee-5b1b-4dc3-a7d5-c06894c46c29",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56410fff-8a35-4816-853e-debb35899179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CRIME scraping process...\n",
      "\n",
      "--- STATISTICS (Before filtering) ---\n",
      "data_source\n",
      "2023_Integration    416\n",
      "2025_Current        400\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Final Scraped Data ---\n",
      "                 city         country  crime_index  safety_index   data_source\n",
      "city_index                                                                    \n",
      "1           Amsterdam     Netherlands         25.7          74.3  2025_Current\n",
      "2              Athens          Greece         55.2          44.8  2025_Current\n",
      "3           Barcelona           Spain         51.9          48.1  2025_Current\n",
      "4             Belfast  United Kingdom         48.0          52.0  2025_Current\n",
      "5            Belgrade          Serbia         37.8          62.2  2025_Current\n",
      "...               ...             ...          ...           ...           ...\n",
      "57             Vienna         Austria         28.2          71.8  2025_Current\n",
      "58            Vilnius       Lithuania         30.1          69.9  2025_Current\n",
      "59             Warsaw          Poland         25.4          74.6  2025_Current\n",
      "60             Zagreb         Croatia         21.4          78.6  2025_Current\n",
      "61             Zurich     Switzerland         23.4          76.6  2025_Current\n",
      "\n",
      "[61 rows x 5 columns]\n",
      "\n",
      "Used sources for the final result:\n",
      "data_source\n",
      "2025_Current    61\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def scrape_numbeo_crime(url, year_tag):\n",
    "    \"\"\"\n",
    "    Scrapes crime and safety index data from Numbeo ranking pages\n",
    "    and applies basic cleaning.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers_ua = {\n",
    "            'User-Agent': (\n",
    "                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                'Chrome/91.0.4472.124 Safari/537.36'\n",
    "            )\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers_ua)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Numbeo ranking table usually has id=\"t2\"\n",
    "        table = soup.find(\"table\", {\"id\": \"t2\"})\n",
    "        if not table:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Expected table columns\n",
    "        headers = [\"Rank\", \"City\", \"Crime_Index\", \"Safety_Index\"]\n",
    "\n",
    "        rows_data = []\n",
    "        for tr in table.find_all(\"tr\")[1:]:\n",
    "            cells = tr.find_all(\"td\")\n",
    "            if len(cells) >= 4:\n",
    "                row = [cell.get_text(strip=True) for cell in cells]\n",
    "                rows_data.append(row[:4])\n",
    "\n",
    "        df = pd.DataFrame(rows_data, columns=headers)\n",
    "        df['data_source'] = year_tag\n",
    "\n",
    "        # Convert numeric columns\n",
    "        df['Crime_Index'] = pd.to_numeric(df['Crime_Index'], errors='coerce')\n",
    "        df['Safety_Index'] = pd.to_numeric(df['Safety_Index'], errors='coerce')\n",
    "\n",
    "        # --------------------\n",
    "        # Data Cleaning\n",
    "        # --------------------\n",
    "\n",
    "        # Extract country from city string\n",
    "        df['Country'] = (\n",
    "            df['City']\n",
    "            .str.split(',')\n",
    "            .str[-1]\n",
    "            .str.strip()\n",
    "            .apply(unidecode.unidecode)\n",
    "        )\n",
    "\n",
    "        # Clean city name\n",
    "        df['City'] = (\n",
    "            df['City']\n",
    "            .str.split(',')\n",
    "            .str[0]\n",
    "            .str.strip()\n",
    "            .apply(unidecode.unidecode)\n",
    "        )\n",
    "\n",
    "        # Normalize column names\n",
    "        df.columns = (\n",
    "            df.columns\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "            .str.replace(' ', '_')\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {year_tag}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def scrape_crime_smart_fallback(city_name):\n",
    "    \"\"\"\n",
    "    Tries multiple city name variants to fetch crime data\n",
    "    from individual Numbeo city pages.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # Variant 1: Name before parentheses\n",
    "    var_a = city_name.split('(')[0].strip().replace(\" \", \"-\").title()\n",
    "    candidates.append(var_a)\n",
    "\n",
    "    # Variant 2: Name inside parentheses\n",
    "    match = re.search(r'\\((.*?)\\)', city_name)\n",
    "    if match:\n",
    "        var_b = match.group(1).strip().replace(\" \", \"-\").title()\n",
    "        candidates.append(var_b)\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "    for candidate in candidates:\n",
    "        url = f\"https://www.numbeo.com/crime/in/{candidate}\"\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            values = {\n",
    "                'crime_index': None,\n",
    "                'safety_index': None\n",
    "            }\n",
    "\n",
    "            label_map = {\n",
    "                'crime_index': \"Crime Index:\",\n",
    "                'safety_index': \"Safety Index:\"\n",
    "            }\n",
    "\n",
    "            found_data = False\n",
    "\n",
    "            for col_name, label_text in label_map.items():\n",
    "                label_el = soup.find(string=re.compile(re.escape(label_text)))\n",
    "                if label_el:\n",
    "                    parent = label_el.parent\n",
    "                    value_cell = parent.find_next(\"td\")\n",
    "                    if value_cell:\n",
    "                        raw_text = value_cell.get_text(strip=True)\n",
    "                        match_num = re.search(r\"(\\d+\\.\\d+)\", raw_text)\n",
    "                        if match_num:\n",
    "                            values[col_name] = float(match_num.group(1))\n",
    "                            found_data = True\n",
    "\n",
    "            if found_data:\n",
    "                return values\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return None\n",
    "\n",
    "# MAIN EXECUTION\n",
    "\n",
    "print(\"Starting CRIME scraping process...\")\n",
    "\n",
    "df_list = [\n",
    "    scrape_numbeo_crime(url, tag)\n",
    "    for tag, url in URLS_CRIME.items()\n",
    "]\n",
    "\n",
    "df_list = [df for df in df_list if not df.empty]\n",
    "\n",
    "if df_list:\n",
    "    df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # --------------------\n",
    "    # Statistics (Before filtering)\n",
    "    # --------------------\n",
    "    print(\"\\n--- STATISTICS (Before filtering) ---\")\n",
    "    print(df_combined['data_source'].value_counts())\n",
    "\n",
    "    # Prioritize latest data\n",
    "    df_combined['sort_helper'] = df_combined['data_source'].apply(\n",
    "        lambda x: 0 if '2025' in x else 1\n",
    "    )\n",
    "    df_combined = df_combined.sort_values('sort_helper')\n",
    "\n",
    "    # Remove duplicates, keeping latest source\n",
    "    df_unique = df_combined.drop_duplicates(\n",
    "        subset=['city'],\n",
    "        keep='first'\n",
    "    ).copy()\n",
    "\n",
    "    # Remove excluded cities\n",
    "    df_unique = df_unique[~df_unique['city'].isin(CITIES_TO_EXCLUDE)]\n",
    "\n",
    "    # Keep only significant cities\n",
    "    REFINED_CITIES = [\n",
    "        city for city in SIGNIFICANT_EUROPEAN_CITIES\n",
    "        if city not in CITIES_TO_EXCLUDE\n",
    "    ]\n",
    "\n",
    "    df_final = df_unique[df_unique['city'].isin(REFINED_CITIES)].copy()\n",
    "\n",
    "    # --------------------\n",
    "    # Final Columns\n",
    "    # --------------------\n",
    "    cols_to_keep = [\n",
    "        'city',\n",
    "        'country',\n",
    "        'crime_index',\n",
    "        'safety_index',\n",
    "        'data_source'\n",
    "    ]\n",
    "    df_final = df_final[cols_to_keep]\n",
    "\n",
    "    # Sort and index\n",
    "    df_final = df_final.sort_values('city').reset_index(drop=True)\n",
    "    df_final.index = df_final.index + 1\n",
    "    df_final.index.name = 'city_index'\n",
    "\n",
    "    print(\"\\n--- Final Scraped Data ---\")\n",
    "    print(df_final)\n",
    "\n",
    "    print(\"\\nUsed sources for the final result:\")\n",
    "    print(df_final['data_source'].value_counts())\n",
    "\n",
    "else:\n",
    "    print(\"No data scraped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eccc98b-0f7d-49d5-8a15-38b6ec90417a",
   "metadata": {},
   "source": [
    "### Missing Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edfa9edd-cc3c-4c06-bfd4-bcbb4c77623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- REPORT DISCREPANCIES ---\n",
      "Number of searched cities: 64\n",
      "Found cities: 61\n",
      "Missing cities: 3\n",
      "\n",
      "Cities not found:\n",
      " Dubrovnik\n",
      " Salzburg\n",
      " Valletta\n"
     ]
    }
   ],
   "source": [
    "# Identify Missing Cities\n",
    "\n",
    "cities_we_wanted = set(REFINED_CITIES)\n",
    "cities_we_got = set(df_final['city'].unique())\n",
    "\n",
    "# Cities present in the reference list but missing in final data\n",
    "missing_cities = cities_we_wanted - cities_we_got\n",
    "\n",
    "# Report\n",
    "print(\"\\n--- REPORT DISCREPANCIES ---\")\n",
    "print(f\"Number of searched cities: {len(cities_we_wanted)}\")\n",
    "print(f\"Found cities: {len(cities_we_got)}\")\n",
    "print(f\"Missing cities: {len(missing_cities)}\")\n",
    "\n",
    "if missing_cities:\n",
    "    print(\"\\nCities not found:\")\n",
    "    for city in sorted(missing_cities):\n",
    "        print(f\" {city}\")\n",
    "else:\n",
    "    print(\"No missing city!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f258b7d6-743f-4072-bffa-5a3a66f8110b",
   "metadata": {},
   "source": [
    "### Recover Missing Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ddd0d7-b0d6-4669-89b1-7bf66db74675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RECOVERING MISSING CITIES ---\n",
      "FOUND (Crime: 17.77)nik... \n",
      "FOUND (Crime: 36.24)ta... \n",
      "FOUND (Crime: 20.5)urg... \n",
      "\n",
      "--- Final Scraped Data ---\n",
      "                 city      country  crime_index  safety_index  \\\n",
      "city_index                                                      \n",
      "55          Stockholm       Sweden        46.50         53.50   \n",
      "56          Stuttgart      Germany        30.40         69.60   \n",
      "57            Tallinn      Estonia        21.70         78.30   \n",
      "58           Valencia        Spain        34.60         65.40   \n",
      "59           Valletta     Valletta        36.24         63.76   \n",
      "60             Vienna      Austria        28.20         71.80   \n",
      "61            Vilnius    Lithuania        30.10         69.90   \n",
      "62             Warsaw       Poland        25.40         74.60   \n",
      "63             Zagreb      Croatia        21.40         78.60   \n",
      "64             Zurich  Switzerland        23.40         76.60   \n",
      "\n",
      "                     data_source  \n",
      "city_index                        \n",
      "55                  2025_Current  \n",
      "56                  2025_Current  \n",
      "57                  2025_Current  \n",
      "58                  2025_Current  \n",
      "59          Single_Page_Recovery  \n",
      "60                  2025_Current  \n",
      "61                  2025_Current  \n",
      "62                  2025_Current  \n",
      "63                  2025_Current  \n",
      "64                  2025_Current  \n",
      "\n",
      "Used sources for the final result:\n",
      "data_source\n",
      "2025_Current            61\n",
      "Single_Page_Recovery     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- VERIFICATION: RECOVERED CITIES ---\n",
      "                 city  crime_index  safety_index           data_source\n",
      "city_index                                                            \n",
      "14          Dubrovnik        17.77         82.23  Single_Page_Recovery\n",
      "51           Salzburg        20.50         79.50  Single_Page_Recovery\n",
      "59           Valletta        36.24         63.76  Single_Page_Recovery\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# Recovery Process\n",
    "# --------------------------------------------------\n",
    "\n",
    "if missing_cities:\n",
    "    print(\"\\n--- RECOVERING MISSING CITIES ---\")\n",
    "\n",
    "    new_rows = []\n",
    "\n",
    "    for city in missing_cities:\n",
    "        print(f\"üîç Searching: {city}...\", end=\" \")\n",
    "\n",
    "        # Courtesy delay to avoid aggressive requests\n",
    "        time.sleep(1)\n",
    "\n",
    "        val_dict = scrape_crime_smart_fallback(city)\n",
    "\n",
    "        if val_dict:\n",
    "            print(f\"FOUND (Crime: {val_dict.get('crime_index')})\")\n",
    "\n",
    "            row = {\n",
    "                'city': city,\n",
    "                'country': city,\n",
    "                'data_source': 'Single_Page_Recovery'\n",
    "            }\n",
    "            row.update(val_dict)\n",
    "            new_rows.append(row)\n",
    "        else:\n",
    "            print(\"Not found.\")\n",
    "\n",
    "    if new_rows:\n",
    "        df_new = pd.DataFrame(new_rows)\n",
    "        df_final = pd.concat([df_final, df_new], ignore_index=True)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Final Sorting & Indexing\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Sort alphabetically by city\n",
    "df_final = df_final.sort_values(by='city').reset_index(drop=True)\n",
    "\n",
    "# Recreate index starting from 1\n",
    "df_final.index = df_final.index + 1\n",
    "df_final.index.name = 'city_index'\n",
    "\n",
    "print(\"\\n--- Final Scraped Data ---\")\n",
    "print(df_final.tail(10))\n",
    "\n",
    "print(\"\\nUsed sources for the final result:\")\n",
    "print(df_final['data_source'].value_counts())\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Final Check\n",
    "# ======================\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Verification Snippet\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Cities recovered using the smart fallback method\n",
    "recovered_cities_crime = df_final[\n",
    "    df_final['data_source'] == 'Single_Page_Recovery'\n",
    "]\n",
    "\n",
    "print(\"\\n--- VERIFICATION: RECOVERED CITIES ---\")\n",
    "if not recovered_cities_crime.empty:\n",
    "    print(\n",
    "        recovered_cities_crime[\n",
    "            ['city', 'crime_index', 'safety_index', 'data_source']\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    print(\"No cities needed recovery (or none were found).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8d05a-c72d-4c12-ae26-a6cb13bb20f8",
   "metadata": {},
   "source": [
    "### Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3927ac4-8161-4b51-95c3-32a00a33b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File saved as: significant_european_cities_crime_index.csv\n",
      "Directory: C:\\Users\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# Save Final Data to CSV\n",
    "# --------------------------------------------------\n",
    "\n",
    "file_name = 'significant_european_cities_crime_safety_index.csv'\n",
    "\n",
    "try:\n",
    "    df_final.to_csv(file_name, index=False, encoding='utf-8')\n",
    "\n",
    "    print(f\"\\nFile saved as: {file_name}\")\n",
    "    print(f\"Directory: {os.getcwd()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving the CSV: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
